{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/swaraj/PROJECTS/Mews-Reccomendation-System/Experimentation'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/swaraj/PROJECTS/Mews-Reccomendation-System'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Entity\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    news: Path\n",
    "    model_name: str\n",
    "    model_content: str\n",
    "    ind2user: Path\n",
    "    ind2item: Path\n",
    "    batch_size: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cpnfiguration Manager\n",
    "from News_Reccomendation_System.constants import *\n",
    "from News_Reccomendation_System.utils.common import read_yaml, create_directories\n",
    "class ConfigurationManager:                  \n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,                     # These were all defined in constants\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifact_root])\n",
    "\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.Behaviour_model\n",
    "        \n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            train_data_path= config.train_data_path,\n",
    "            test_data_path= config.test_data_path,\n",
    "            model_name= config.model_name,\n",
    "            model_content= config.model_content,\n",
    "            news= config.news,\n",
    "            ind2user= config.ind2user,\n",
    "            ind2item= config.ind2item,\n",
    "            batch_size= params.batch_size\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Components\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "from News_Reccomendation_System import logger\n",
    "from News_Reccomendation_System.utils.common import load_json\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import joblib\n",
    "\n",
    "import ktrain\n",
    "\n",
    "\n",
    "class MindDataset(Dataset):\n",
    "    # A fairly simple torch dataset module that can take a pandas dataframe (as above), \n",
    "    # and convert the relevant fields into a dictionary of arrays that can be used in a dataloader\n",
    "    def __init__(self, df):\n",
    "        # Create a dictionary of tensors out of the dataframe\n",
    "        self.data = {\n",
    "            'userIdx' : torch.tensor(df.userIdx.values),\n",
    "            'click' : torch.tensor(df.click.values),\n",
    "            'noclick' : torch.tensor(df.noclick.values)\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.data['userIdx'])\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.data.items()}\n",
    "    \n",
    "\n",
    "# Build a matrix factorization model\n",
    "class NewsMF(pl.LightningModule):\n",
    "    def __init__(self, num_users, num_items, dim = 10):\n",
    "        super().__init__()\n",
    "        self.dim=dim\n",
    "        self.useremb = nn.Embedding(num_embeddings=num_users, embedding_dim=dim)\n",
    "        self.itememb = nn.Embedding(num_embeddings=num_items, embedding_dim=dim)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        batch_size = user.size(0)\n",
    "        uservec = self.useremb(user)\n",
    "        itemvec = self.itememb(item)\n",
    "\n",
    "        score = (uservec*itemvec).sum(-1).unsqueeze(-1)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_size = batch['userIdx'].size(0)\n",
    "\n",
    "        score_click = self.forward(batch['userIdx'], batch['click'])\n",
    "        score_noclick = self.forward(batch['userIdx'], batch['noclick'])\n",
    "        \n",
    "        scores_all = torch.concat((score_click, score_noclick), dim=1)\n",
    "        # Compute loss as cross entropy (categorical distribution between the clicked and the no clicked item)\n",
    "        loss = F.cross_entropy(input=scores_all, target=torch.zeros(batch_size, device=scores_all.device).long())\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # for now, just do the same computation as during training\n",
    "        loss = self.training_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_data(self):\n",
    "        train = pd.read_csv(self.config.train_data_path, sep= '\\t')\n",
    "        valid = pd.read_csv(self.config.test_data_path, sep= '\\t')\n",
    "\n",
    "        return train, valid\n",
    "\n",
    "    def get_hashes(self):\n",
    "        ind2user = load_json(Path(self.config.ind2user))\n",
    "        ind2item = load_json(Path(self.config.ind2item))\n",
    "\n",
    "        return ind2item, ind2user\n",
    "            \n",
    "\n",
    "    def build_datasets(self, train, valid):\n",
    "        bs = self.config.batch_size\n",
    "        ds_train = MindDataset(train)\n",
    "        train_loader = DataLoader(ds_train, batch_size=bs, shuffle=True)\n",
    "        ds_valid = MindDataset(valid)\n",
    "        valid_loader = DataLoader(ds_valid, batch_size=bs, shuffle=False)\n",
    "\n",
    "        # batch = next(iter(train_loader))\n",
    "        \n",
    "        return train_loader, valid_loader\n",
    "    \n",
    "    def model_training(self, train_loader, valid_loader, ind2item, ind2user):\n",
    "\n",
    "        mf_model = NewsMF(num_users=len(ind2user)+1, num_items = len(ind2item)+1)\n",
    "    \n",
    "        trainer = pl.Trainer(max_epochs=10)\n",
    "        trainer.fit(model=mf_model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "\n",
    "        joblib.dump(mf_model, os.path.join(self.config.root_dir, self.config.model_name))\n",
    "\n",
    "\n",
    "    def model_training_2(self):\n",
    "        df = pd.read_csv(self.config.news, sep= '\\t',\n",
    "                         names=[\"itemId\",\"category\",\n",
    "                                \"subcategory\",\n",
    "                                \"title\",\n",
    "                                \"abstract\",\n",
    "                                \"url\",\n",
    "                                \"title_entities\",\n",
    "                                \"abstract_entities\"])\n",
    "\n",
    "        df.dropna(inplace= True)\n",
    "        df.drop_duplicates(inplace= True)\n",
    "        df['article'] = df.apply(lambda row: row['title'] + row['abstract'], axis= 1)\n",
    "        corpus = list(df['article'])\n",
    "        del df\n",
    "        tm = ktrain.text.get_topic_model(texts= corpus, n_features= 100000)\n",
    "        tm.build(corpus, threshold= 0.25)\n",
    "        tm.train_recommender()\n",
    "\n",
    "        joblib.dump(tm, os.path.join(self.config.root_dir, self.config.model_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_NAME = '04 ---- Model Training Step'\n",
    "\n",
    "\n",
    "\n",
    "class ModelTrainingPipeline:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        config = ConfigurationManager()\n",
    "        model_trainer_config = config.get_model_trainer_config()\n",
    "        model_trainer = ModelTrainer(config= model_trainer_config)\n",
    "        train, valid = model_trainer.get_data()\n",
    "        ind2item, ind2user = model_trainer.get_hashes()\n",
    "        train_loader, valid_loader = model_trainer.build_datasets(train= train,\n",
    "                                                                  valid= valid)\n",
    "        model_trainer.model_training(train_loader= train_loader,\n",
    "                                     valid_loader= valid_loader,\n",
    "                                     ind2item= ind2item,\n",
    "                                     ind2user= ind2user)\n",
    "        model_trainer.model_training_2()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def run_model_trainer():\n",
    "\n",
    "    try:\n",
    "        logger.info(f' >>>>>>> Step {STEP_NAME} started <<<<<<<<<<<')\n",
    "        obj = ModelTrainingPipeline()\n",
    "        obj.main()\n",
    "        logger.info(f' >>>>>>> Step {STEP_NAME} completed <<<<<<<<<<<\\n\\nx====================x')\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.exception(e)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-25 12:27:37,301: INFO: 1146969740:  >>>>>>> Step 04 ---- Model Training Step started <<<<<<<<<<<]\n",
      "[2023-10-25 12:27:37,314: INFO: common: yaml file: config/config.yaml loaded succesfully]\n",
      "[2023-10-25 12:27:37,326: INFO: common: yaml file: params.yaml loaded succesfully]\n",
      "[2023-10-25 12:27:37,330: INFO: common: yaml file: schema.yaml loaded succesfully]\n",
      "[2023-10-25 12:27:37,333: INFO: common: Created directory at : artifacts]\n",
      "[2023-10-25 12:27:37,336: INFO: common: Created directory at : artifacts/model_trainer]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-25 12:27:38,301: INFO: common: JSON file loaded succesfully from: artifacts/data_transformation/ind2user.json]\n",
      "[2023-10-25 12:27:39,401: INFO: common: JSON file loaded succesfully from: artifacts/data_transformation/ind2uitem.json]\n",
      "[2023-10-25 12:27:40,289: INFO: setup: GPU available: False, used: False]\n",
      "[2023-10-25 12:27:40,291: INFO: setup: TPU available: False, using: 0 TPU cores]\n",
      "[2023-10-25 12:27:40,293: INFO: setup: IPU available: False, using: 0 IPUs]\n",
      "[2023-10-25 12:27:40,299: INFO: setup: HPU available: False, using: 0 HPUs]\n",
      "[2023-10-25 12:27:40,479: INFO: model_summary: \n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | useremb | Embedding | 500 K \n",
      "1 | itememb | Embedding | 512 K \n",
      "--------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.051     Total estimated model params size (MB)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f3c8d281864c60a87b17af82a0c195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swaraj/PROJECTS/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/home/swaraj/PROJECTS/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0061acc5d67461fa8d9f7332d8af069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670a7f51a0b04d62b04a8c0e20e25b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aeab1d8beed49bea1b374d34e0dc4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d064ddfe196d4c788875a45fb767ea97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8692a4f7b64140a18f2cc950023609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7708b5a0d29478fb77d362acb646c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9900a132e1124257b7c47a3f79ddd4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d245daf3fece4684ae935c38c3709a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cee78000c54324b5376cd115072595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4591358fe04a409283e50615cedd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e132af0d4aee43a1bce7c20012dbe087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-25 12:29:07,666: INFO: fit_loop: `Trainer.fit` stopped: `max_epochs=10` reached.]\n",
      "n_topics automatically set to 155\n",
      "lang: en\n",
      "preprocessing texts...\n",
      "fitting model...\n",
      "iteration: 1 of max_iter: 5\n",
      "iteration: 2 of max_iter: 5\n",
      "iteration: 3 of max_iter: 5\n",
      "iteration: 4 of max_iter: 5\n",
      "iteration: 5 of max_iter: 5\n",
      "done.\n",
      "done.\n",
      "[2023-10-25 12:35:46,677: INFO: 1146969740:  >>>>>>> Step 04 ---- Model Training Step completed <<<<<<<<<<<\n",
      "\n",
      "x====================x]\n"
     ]
    }
   ],
   "source": [
    "run_model_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
