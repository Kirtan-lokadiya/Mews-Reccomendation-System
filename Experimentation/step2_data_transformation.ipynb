{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/swaraj/PROJECTS/Mews-Reccomendation-System/Experimentation'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/swaraj/PROJECTS/Mews-Reccomendation-System'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTITY\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path_usr: Path\n",
    "    data_path_news: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from News_Reccomendation_System.constants import *\n",
    "from News_Reccomendation_System.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-25 10:57:09,599: INFO: common: yaml file: config/config.yaml loaded succesfully]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigBox({'artifact_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'local_data_file': 'news.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'data_transformation': {'root_dir': 'artifacts/data_transformation', 'data_path_usr': 'artifacts/data_ingestion/news.tsv'}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:                  \n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,                     # These were all defined in constants\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifact_root])\n",
    "\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "\n",
    "        config = self.config.data_transformation\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_configuration = DataTransformationConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            data_path_usr= config.data_path_usr,\n",
    "            data_path_news= config.data_path_news\n",
    "        )\n",
    "\n",
    "        return data_transformation_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from News_Reccomendation_System import logger\n",
    "from News_Reccomendation_System.utils.common import save_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DataTransformtion:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def user_data(self):\n",
    "        df = pd.read_csv(self.config.data_path_usr,\n",
    "                         sep=\"\\t\",\n",
    "                         names=[\"impressionId\",\n",
    "                                \"userId\",\n",
    "                                \"timestamp\",\n",
    "                                \"click_history\",\n",
    "                                \"impressions\"]\n",
    "                                )\n",
    "        return df\n",
    "    \n",
    "    def news_data(self):\n",
    "        df = pd.read_csv(self.config.data_path_news,\n",
    "                         sep='\\t',\n",
    "                         names=[\"itemId\",\n",
    "                                \"category\",\n",
    "                                \"subcategory\",\n",
    "                                \"title\",\"abstract\",\n",
    "                                \"url\",\n",
    "                                \"title_entities\",\n",
    "                                \"abstract_entities\"]\n",
    "                                )\n",
    "        return df\n",
    "    \n",
    "    def indexize_users(self, raw_behaviour: pd.DataFrame):\n",
    "        ## Indexize users\n",
    "        unique_userIds = raw_behaviour['userId'].unique()\n",
    "        # Allocate a unique index for each user, but let the zeroth index be a UNK index:\n",
    "        ind2user = {idx +1: itemid for idx, itemid in enumerate(unique_userIds)}\n",
    "        user2ind = {itemid : idx for idx, itemid in ind2user.items()}\n",
    "        print(f\"We have {len(user2ind)} unique users in the dataset\")\n",
    "\n",
    "        save_json(path= os.path.join(self.config.root_dir, 'ind2user.json'), data= ind2user)\n",
    "        save_json(path= os.path.join(self.config.root_dir, 'user2ind.json'), data= user2ind)\n",
    "        # Create a new column with userIdx:\n",
    "        raw_behaviour['userIdx'] = raw_behaviour['userId'].map(lambda x: user2ind.get(x,0))\n",
    "                \n",
    "        return raw_behaviour\n",
    "    \n",
    "    def get_iten2ind_hash(self, news :pd.DataFrame):\n",
    "        ind2item = {idx +1: itemid for idx, itemid in enumerate(news['itemId'].values)}\n",
    "        item2ind = {itemid : idx for idx, itemid in ind2item.items()}\n",
    "\n",
    "        save_json(path= os.path.join(self.config.root_dir, 'ind2uitem.json'), data= ind2item)\n",
    "        save_json(path= os.path.join(self.config.root_dir, 'item2ind.json'), data= item2ind)\n",
    "\n",
    "        return item2ind\n",
    "    \n",
    "    def indexise_click_history(self, item2ind: dict, raw_behaviour: pd.DataFrame):\n",
    "\n",
    "        def process_click_history(s):\n",
    "            list_of_strings = str(s).split(\" \")\n",
    "            return [item2ind.get(l, 0) for l in list_of_strings]\n",
    "\n",
    "        raw_behaviour['click_history_idx'] = raw_behaviour.click_history.map(lambda s:  process_click_history(s))\n",
    "\n",
    "        return raw_behaviour\n",
    "    \n",
    "\n",
    "    def one_click_no_click(self, item2ind: dict, raw_behaviour: pd.DataFrame):\n",
    "\n",
    "        def process_impression(s):\n",
    "            list_of_strings = s.split(\" \")\n",
    "            itemid_rel_tuple = [l.split(\"-\") for l in list_of_strings]\n",
    "            noclicks = []\n",
    "            for entry in itemid_rel_tuple:\n",
    "                if entry[1] =='0':\n",
    "                    noclicks.append(entry[0])\n",
    "                if entry[1] =='1':\n",
    "                    click = entry[0]\n",
    "            return noclicks, click\n",
    "\n",
    "        raw_behaviour['noclicks'], raw_behaviour['click'] = zip(*raw_behaviour['impressions'].map(process_impression))\n",
    "        # We can then indexize these two new columns:\n",
    "        raw_behaviour['noclicks'] = raw_behaviour['noclicks'].map(lambda list_of_strings: [item2ind.get(l, 0) for l in list_of_strings])\n",
    "        raw_behaviour['click'] = raw_behaviour['click'].map(lambda x: item2ind.get(x,0))\n",
    "\n",
    "        return raw_behaviour\n",
    "\n",
    "\n",
    "    def conver_datetime_to_hrs(self, raw_behaviour: pd.DataFrame):\n",
    "\n",
    "        raw_behaviour['epochhrs'] = pd.to_datetime(raw_behaviour['timestamp']).values.astype(np.int64)/(1e6)/1000/3600\n",
    "        raw_behaviour['epochhrs'] = raw_behaviour['epochhrs'].round()\n",
    "\n",
    "        return raw_behaviour\n",
    "    \n",
    "\n",
    "    def get_user_behaviour(self, raw_behaviour: pd.DataFrame):\n",
    "\n",
    "        raw_behaviour['noclick'] = raw_behaviour['noclicks'].map(lambda x : x[0])\n",
    "        behaviour = raw_behaviour[['epochhrs','userIdx','click_history_idx','noclick','click']]\n",
    "\n",
    "        return behaviour\n",
    "    \n",
    "\n",
    "    def train_test_spilt_behaviour(self, behaviour):\n",
    "\n",
    "        # Let us use the last 10pct of the data as our validation data:\n",
    "        test_time_th = behaviour['epochhrs'].quantile(0.9)\n",
    "        train = behaviour[behaviour['epochhrs']< test_time_th]\n",
    "        valid =  behaviour[behaviour['epochhrs']>= test_time_th]\n",
    "\n",
    "        train.to_csv(os.path.join(self.config.root_dir, 'train.tsv'), index = False, sep= '\\t')\n",
    "        valid.to_csv(os.path.join(self.config.root_dir, 'valid.tsv'), index = False, sep= '\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_NAME = '03 ---- Data Transformation Step'\n",
    "\n",
    "\n",
    "\n",
    "class DataTransformationPipeline:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def main(self):\n",
    "        \n",
    "\n",
    "\n",
    "        config = ConfigurationManager()\n",
    "        data_transformation_config = config.get_data_transformation_config()\n",
    "        data_transformation = DataTransformtion(config= data_transformation_config)\n",
    "        raw_behaviour = data_transformation.user_data()\n",
    "        news = data_transformation.news_data()\n",
    "        item2ind = data_transformation.get_iten2ind_hash(news= news)\n",
    "        raw_behaviour = data_transformation.indexize_users(raw_behaviour= raw_behaviour)\n",
    "        raw_behaviour = data_transformation.indexise_click_history(raw_behaviour= raw_behaviour, item2ind= item2ind)\n",
    "        raw_behaviour = data_transformation.one_click_no_click(raw_behaviour= raw_behaviour, item2ind= item2ind)\n",
    "        raw_behaviour = data_transformation.conver_datetime_to_hrs(raw_behaviour= raw_behaviour)\n",
    "        behaviour = data_transformation.get_user_behaviour(raw_behaviour= raw_behaviour)\n",
    "        data_transformation.train_test_spilt_behaviour(behaviour= behaviour)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_data_transformation():\n",
    "    try:\n",
    "        logger.info(f' >>>>>>> Step {STEP_NAME} started <<<<<<<<<<<')\n",
    "        obj = DataTransformationPipeline()\n",
    "        obj.main()\n",
    "        logger.info(f' >>>>>>> Step {STEP_NAME} completed <<<<<<<<<<<\\n\\nx====================x')\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.exception(e)\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-25 10:58:54,858: INFO: 1062367176:  >>>>>>> Step 03 ---- Data Transformation Step started <<<<<<<<<<<]\n",
      "[2023-10-25 10:58:54,876: INFO: common: yaml file: config/config.yaml loaded succesfully]\n",
      "[2023-10-25 10:58:54,889: INFO: common: yaml file: params.yaml loaded succesfully]\n",
      "[2023-10-25 10:58:54,898: INFO: common: yaml file: schema.yaml loaded succesfully]\n",
      "[2023-10-25 10:58:54,904: INFO: common: Created directory at : artifacts]\n",
      "[2023-10-25 10:58:54,934: INFO: common: Created directory at : artifacts/data_transformation]\n",
      "We have 50000 unique users in the dataset\n",
      "[2023-10-25 10:59:38,071: INFO: 1062367176:  >>>>>>> Step 03 ---- Data Transformation Step completed <<<<<<<<<<<\n",
      "\n",
      "x====================x]\n"
     ]
    }
   ],
   "source": [
    "run_data_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
